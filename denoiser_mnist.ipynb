{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30042,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\nAn autoencoder is a neural network that learns to copy its input to its output. It has an internal (hidden) layer that describes a code used to represent the input, and it is constituted by two main parts: an encoder that maps the input into the code, and a decoder that maps the code to a reconstruction of the original input.\nAutoencoder are quiet strange type of neural network. The dimension of input is same as the dimension of the output.\n","metadata":{}},{"cell_type":"markdown","source":"<img src = 'https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/04/29201743/Blog_info_29-04-2020-R-01-1024x438.png'>","metadata":{}},{"cell_type":"markdown","source":"## Denoising Autoencoder  \nA Denoising Autoencoder is a modification on the autoencoder. Here, we fed our autoencoder with the noise images and train the with their correspoinding non noised images, then it can just learn the data.The encoder network reduced the dimension of the noised image, this is called code then this code is fed to the decoder where it denoised the reduced noised images.","metadata":{}},{"cell_type":"markdown","source":"<img src = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRLqQ6l3BnxIERwslN8F9JVVhVUu1a1U_C_iQ&usqp=CAU\">","metadata":{}},{"cell_type":"markdown","source":"## Import necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport tensorflow as tf\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPool2D, UpSampling2D,Dropout\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load our data \nHere, we are using MNIST dataset ","metadata":{}},{"cell_type":"code","source":"from keras.datasets import mnist\n(x_train,y_train),(x_test,y_test) = mnist.load_data()\n# to get the shape of the data \nprint(\"x_train shape:\",x_train.shape)\nprint(\"x_test shape\", x_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## understanding and visualizing our data\nThe MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.\nThe MNIST database contains 60,000 training images and 10,000 testing images, with their correspoinding labels. These images are grayscale image of 28 by 28 pixels.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\nfor i in range(25):\n  plt.subplot(5,5,i+1)\n  plt.title(str(y_train[i]),fontsize = 16, color = 'black', pad = 2)\n  plt.imshow(x_train[i], cmap = plt.cm.binary )\n  plt.xticks([])\n  plt.yticks([])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spliting test data for validation and testing\n\nHere, we will divide test data into validation data and test data so that we can use validation data to avoid overfitting and can use testing data to test the performance of our CNN model. Here we have used 90% of our test data for validation and remaining 10% for testing","metadata":{}},{"cell_type":"code","source":"val_images = x_test[:9000]\ntest_images = x_test[9000:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing and reshaping\n\nHere, pixel value for our training, validating and testing images are in range between 0 to 255. In order to reduce data inconsistency we have to normalize the data\nAnd, we are reshaping our images so that all images are of same shape and all can be feed into the network \n\nHere, train images have maximum value of 255. and minimum value of 0. So, for normalizing we simply can divide data by 255\n\nx = (x - x.min()) / (x.max() - x.min())","metadata":{}},{"cell_type":"code","source":"val_images = val_images.astype('float32') / 255.0\nval_images = np.reshape(val_images,(val_images.shape[0],28,28,1))\n\ntest_images = test_images.astype('float32') / 255.0\ntest_images = np.reshape(test_images,(test_images.shape[0],28,28,1))\n\ntrain_images = x_train.astype(\"float32\") / 255.0\ntrain_images = np.reshape(train_images, (train_images.shape[0],28,28,1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding noise\nHere we are adding random numbers the our images so that our image look noisy, and we can feed them as input to our network along with non noisy image as target so that our network learns to denoise image","metadata":{}},{"cell_type":"code","source":"factor = 0.39\ntrain_noisy_images = train_images + factor * np.random.normal(loc = 0.0,scale = 1.0,size = train_images.shape)\nval_noisy_images = val_images + factor * np.random.normal(loc = 0.0,scale = 1.0,size = val_images.shape)\ntest_noisy_images = test_images + factor * np.random.normal(loc = 0.0,scale = 1.0,size = test_images.shape)\n\n# here maximum pixel value for our images may exceed 1 so we have to clip the images\ntrain_noisy_images = np.clip(train_noisy_images,0.,1.)\nval_noisy_images = np.clip(val_noisy_images,0.,1.)\ntest_noisy_images = np.clip(test_noisy_images,0.,1.)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing images after adding noise","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (8,8))\n\nfor i in range(25):      \n      plt.subplot(5,5,i+1)\n      plt.title(str(y_train[i]),fontsize = 16, color = 'black', pad = 2)\n      plt.imshow(train_noisy_images[i].reshape(1,28,28)[0], cmap = plt.cm.binary )\n      plt.xticks([])\n      plt.yticks([])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining our autoencoder model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n# encoder network\nmodel.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', padding = 'same', input_shape = (28,28,1)))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2),strides = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 512, kernel_size = (3,3), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 512, kernel_size = (2,2),strides = (2,2), activation = 'relu', padding = 'same'))\n\n\n\n# decoder network\nmodel.add(Conv2D(filters = 512, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n\nmodel.add(tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (2,2), strides = (2,2),activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n\n\nmodel.add(tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (2,2),strides = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(Conv2D(filters = 64, kernel_size = (2,2), activation = 'relu', padding = 'same'))\nmodel.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(Conv2D(filters = 1, kernel_size = (2,2), activation = 'relu', padding = 'same'))\n\n\n# to get the summary of the model\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compile model","metadata":{}},{"cell_type":"code","source":"OPTIMIZER =  tf.keras.optimizers.Adam(learning_rate = 0.001)\nLOSS = 'mean_squared_error'\nmodel.compile(optimizer =OPTIMIZER, loss = LOSS, metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting the model","metadata":{}},{"cell_type":"code","source":"EPOCHS = 5\nBATCH_SIZE = 256\nVALIDATION = (val_noisy_images, val_images)\nhistory = model.fit(train_noisy_images, train_images,batch_size = BATCH_SIZE,epochs = EPOCHS, validation_data = VALIDATION)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model evaluation \nloss and accuracy curve","metadata":{}},{"cell_type":"code","source":"plt.subplot(2,1,1)\nplt.plot( history.history['loss'], label = 'loss')\nplt.plot( history.history['val_loss'], label = 'val_loss')\nplt.legend(loc = 'best')\nplt.subplot(2,1,2)\nplt.plot( history.history['accuracy'], label = 'accuracy')\nplt.plot( history.history['val_accuracy'], label = 'val_accuracy')\nplt.legend(loc = 'best')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing our predicted images along with real and noised images","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (18,18))\nfor i in range(10,19):\n    plt.subplot(9,9,i)\n    if(i == 14):\n        plt.title('Real Images', fontsize = 25, color = 'Green') \n    plt.imshow(test_images[i].reshape(1,28,28)[0], cmap = plt.cm.binary)\nplt.show()\n\n\nplt.figure(figsize = (18,18))\nfor i in range(10,19):\n    if(i == 15):\n        plt.title('Noised Images', fontsize = 25, color = 'red') \n    plt.subplot(9,9,i)\n    plt.imshow(test_noisy_images[i].reshape(1,28,28)[0], cmap = plt.cm.binary)\nplt.show()\n\n\nplt.figure(figsize = (18,18))\nfor i in range(10,19):  \n    if(i == 15):\n        plt.title('Denoised Images', fontsize = 25, color = 'Blue') \n    \n    plt.subplot(9,9,i)\n    plt.imshow(model.predict(test_noisy_images[i].reshape(1,28,28,1)).reshape(1,28,28)[0], cmap = plt.cm.binary) \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thanks for your visit\n#### Any suggestions to improved this kernel is really appreciated","metadata":{}}]}