{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def def_args(grayscale=False, num_kernels = 64):\n",
    "    '''\n",
    "    @ grayscale: if True, number of input and output channels are set to 1. Otherwise 3\n",
    "    @ training_data: models provided in here have been trained on {BSD400, mnist, BSD300}\n",
    "    @ training_noise: standard deviation of noise during training the denoiser\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser(description='BF_CNN_color')\n",
    "    parser.add_argument('--dir_name', default= '../noise_range_')\n",
    "    parser.add_argument('--kernel_size', default= 3)\n",
    "    parser.add_argument('--padding', default= 1)\n",
    "    parser.add_argument('--num_kernels', default= num_kernels)\n",
    "    parser.add_argument('--num_layers', default= 20)\n",
    "    if grayscale is True:\n",
    "        parser.add_argument('--num_channels', default= 1)\n",
    "    else:\n",
    "        parser.add_argument('--num_channels', default= 3)\n",
    "\n",
    "    args = parser.parse_args('')\n",
    "    return args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BF_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(BF_CNN, self).__init__()\n",
    "\n",
    "        self.padding = args.padding\n",
    "        self.num_kernels = args.num_kernels\n",
    "        self.kernel_size = args.kernel_size\n",
    "        self.num_layers = args.num_layers\n",
    "        self.num_channels = args.num_channels\n",
    "\n",
    "        self.conv_layers = nn.ModuleList([])\n",
    "        self.running_sd = nn.ParameterList([])\n",
    "        self.gammas = nn.ParameterList([])\n",
    "\n",
    "        # self.conv_layers.append(PrintShape())\n",
    "        self.conv_layers.append(nn.Conv2d(self.num_channels,self.num_kernels, self.kernel_size, padding=self.padding , bias=False))\n",
    "\n",
    "        for l in range(1,self.num_layers-1):\n",
    "            # self.conv_layers.append(PrintShape())\n",
    "            self.conv_layers.append(nn.Conv2d(self.num_kernels ,self.num_kernels, self.kernel_size, padding=self.padding , bias=False))\n",
    "            self.running_sd.append( nn.Parameter(torch.ones(1,self.num_kernels,1,1), requires_grad=False) )\n",
    "            g = (torch.randn( (1,self.num_kernels,1,1) )*(2./9./64.)).clamp_(-0.025,0.025)\n",
    "            self.gammas.append(nn.Parameter(g, requires_grad=True) )\n",
    "\n",
    "        self.conv_layers.append(nn.Conv2d(self.num_kernels,self.num_channels, self.kernel_size, padding=self.padding , bias=False))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        relu = nn.ReLU(inplace=True)\n",
    "        x = relu(self.conv_layers[0](x))\n",
    "        for l in range(1,self.num_layers-1):\n",
    "            x = self.conv_layers[l](x)\n",
    "            # BF_BatchNorm\n",
    "            sd_x = torch.sqrt(x.var(dim=(0,2,3) ,keepdim = True, unbiased=False)+ 1e-05)\n",
    "\n",
    "            if self.conv_layers[l].training:\n",
    "                x = x / sd_x.expand_as(x)\n",
    "                self.running_sd[l-1].data = (1-.1) * self.running_sd[l-1].data + .1 * sd_x\n",
    "                x = x * self.gammas[l-1].expand_as(x)\n",
    "\n",
    "            else:\n",
    "                x = x / self.running_sd[l-1].expand_as(x)\n",
    "                x = x * self.gammas[l-1].expand_as(x)\n",
    "\n",
    "            x = relu(x)\n",
    "\n",
    "        x = self.conv_layers[-1](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomCropMNISTDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, crop_size=24, num_crops=1, max_std=0.1, train=True):\n",
    "        self.mnist_dataset = datasets.MNIST(root=root, train=train, transform=None, download=True)\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "        self.num_crops = num_crops\n",
    "        self.max_std = max_std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.mnist_dataset[index]\n",
    "\n",
    "        # Perform random crops\n",
    "        crops = []\n",
    "        for _ in range(self.num_crops):\n",
    "            x = random.randint(0, image.size[0] - self.crop_size)\n",
    "            y = random.randint(0, image.size[1] - self.crop_size)\n",
    "            cropped_image = image.crop((x, y, x + self.crop_size, y + self.crop_size))\n",
    "\n",
    "            # Apply transformations\n",
    "            if self.transform is not None:\n",
    "                cropped_image = self.transform(cropped_image)\n",
    "\n",
    "            # Add Gaussian noise to the cropped image\n",
    "            std_dev = random.uniform(0, self.max_std)\n",
    "            noised_image = self.add_gaussian_noise(cropped_image, std_dev)\n",
    "\n",
    "            crops.append((cropped_image, noised_image, label))\n",
    "\n",
    "        return crops\n",
    "\n",
    "    def add_gaussian_noise(self, image, std_dev):\n",
    "        noise = torch.randn_like(image) * std_dev\n",
    "        noised_image = image + noise\n",
    "        return noised_image\n",
    "\n",
    "# # Example usage:\n",
    "# # Define the transform to normalize and convert to PyTorch tensor\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "\n",
    "# root = 'C:/Users/ANT/Documents/info/IIN_universal_inverse_problem/test_images/grayscale/mnist'\n",
    "# # Create the dataset\n",
    "# mnist_dataset = RandomCropMNISTDataset(root=root, transform=transform, crop_size=24, num_crops=5, max_std=0.1, train=True)\n",
    "\n",
    "# # Access a sample from the dataset\n",
    "# sample = mnist_dataset[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Mean Squared Error (MSE) loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Instantiate the model, optimizer, and dataset\n",
    "args = def_args(grayscale=True)\n",
    "model = BF_CNN(args)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "crop_size = 24\n",
    "\n",
    "mnist_dataset = RandomCropMNISTDataset(root='./data', transform=transform, crop_size=crop_size, num_crops=1, max_std=0.4, train=True)\n",
    "\n",
    "# DataLoader for batching and shuffling\n",
    "dataloader = DataLoader(mnist_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        batch_clean, batch_noised, _ = batch[0]\n",
    "        batch_clean, batch_noised = batch_clean.to(device), batch_noised.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_noised)\n",
    "\n",
    "        # Compute the MSE loss\n",
    "        loss = criterion(outputs, batch_clean)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "torch.save(model.state_dict(), f'bf_cnn_mnist_trained_with_crops_{crop_size}x{crop_size}_{num_epochs}.pth')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
